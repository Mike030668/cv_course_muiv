## Модуль 1. Цифровое изображение и базовая обработка (1–10)

1. Дайте определение цифрового изображения. Чем отличаются **физический** и **логический** пиксель, и почему это важно на практике?
2. Объясните влияние **разрешения**, **dpi/ppi** и **глубины цвета** на качество изображения и объём данных.
3. Сравните человеческий глаз и цифровую камеру как системы формирования изображения: ключевые элементы, различия в адаптации к освещению и цветопередаче.
4. Что такое **дискретизация** по пространству и по яркости? Какие артефакты возникают при недостаточной дискретизации (примеры причин и проявлений)?
5. Сравните цветовые модели **RGB**, **HSI/HSV(HSB)** и **CIE XYZ / CIE L*a*b***: что является “координатами” цвета, где удобнее решать задачи коррекции/сегментации и почему.
6. Опишите свёртку в обработке изображений и различие между **свёрткой** и **корреляцией**. Приведите пример, где это различие принципиально.
7. Сравните шумы (например, гауссов, импульсный/“соль-перец”) и методы подавления: **гауссово сглаживание**, **медианный фильтр**, **усреднение кадров**, **билатеральный фильтр** — когда что выбирать и почему.
8. Объясните идею выделения краёв через градиент: роль производных и свёртки. Сравните операторы **Робертса, Превитта, Собеля, Scharr** (с точки зрения устойчивости к шуму и точности локализации).
9. Что такое компенсация неравномерного освещения? Опишите идею **Retinex (SSR)** и в каких задачах она полезна.
10. Сегментация “простыми” методами: опишите принцип выделения однородных областей (последовательное сканирование/слияние областей) и роль порога δ.

## Модуль 2. Сопоставление изображений и классическая классификация/поиск (11–22)

1. В чём состоит задача **сопоставления (matching/alignment)** изображений? Приведите типовые применения: панорамы, мозаики, 3D-реконструкция.
2. Перечислите основные сложности сопоставления: освещение, геометрические искажения, масштаб/скорость, внутриклассовая изменчивость — и типовые подходы к их преодолению.
3. Сравните подходы: **пиксельные** (кросс-корреляция/SSD/SAD) vs **по ключевым точкам**. Укажите преимущества, ограничения и условия применимости.
4. Детектор Харриса: идея “угла” и почему он устойчивее, чем простое сравнение патчей в лоб. Какие типовые ошибки возникают?
5. Что такое **blob-детекторы** и чем они концептуально отличаются от угловых детекторов?
6. Опишите общий конвейер feature-based matching: детекция → описание (descriptor) → сопоставление → отбраковка выбросов → оценка преобразования.
7. Метод **SIFT**: какие свойства достигаются (масштаб/поворот/частично освещение), за счёт каких этапов (на уровне идеи).
8. **RANSAC**: зачем нужен, что такое “внутренние точки/выбросы”, как выбирается модель и критерий качества.
9. Выбор модели преобразования при совмещении: когда достаточно 2D (аффинное/гомография), а когда требуется 3D-модель. Приведите признаки “нехватки” 2D-модели.
10. “Мешок слов” для изображений: построение визуального словаря, квантование признаков, гистограммы. В чём выигрываем и что теряем?
11. Пространственная пирамида: зачем добавлять пространственное распределение к “мешку слов”, и как это влияет на точность/размерность.
12. Классические дескрипторы для распознавания/поиска: **HOG, LBP** — что именно они кодируют и в каких задачах сильны/слабы.

## Модуль 3. Нейросетевые признаки, классификация, поиск и видео (23–33)

1. Искусственный нейрон и перцептрон: роль весов, bias (смещения) и функции активации. Почему один перцептрон не решает нелинейно-разделимые задачи?
2. Обучение нейросети: форвард-проход, функция потерь, backprop, оптимизация. Сравните **SGD**, mini-batch, **Momentum**, **RMSprop**, **Adam** (по смыслу, не по формулам).
3. Функции активации и функции потерь: как выбор активации связан с задачей (классификация/регрессия) и почему кросс-энтропия часто “логичнее” MSE в классификации.
4. CNN как извлекатель признаков: почему свёртки “подходят” для изображений (локальность, разделение весов), и роль pooling/stride.
5. Выход слоя как **вектор-признак**: как его использовать для (а) классификации (softmax/линейный классификатор), (б) поиска похожих (метрики, k-NN).
6. Визуализация работы нейросетей: какие вопросы помогает решать (активации, важность признаков, диагностика ошибок), и какие инструменты применяются (например, TensorBoard).
7. UMAP vs t-SNE vs PCA: цель, сильные стороны, ограничения. Почему UMAP часто предпочтительнее при большом числе объектов/точек?
8. Fine-tuning: когда он нужен, какие слои обычно “замораживают/размораживают”, и какие риски (переобучение, доменная несостыковка).
9. Архитектурные идеи: **Inception** (факторизация/параллельные ветви) и **MobileNet** (факторизация свёрток). Что даёт выигрыш по ресурсам?
10. Оптический поток: определение, основные применения и типовые проблемы (окклюзии, освещение, движение камеры). Сравните классические методы (Лукас-Канаде, Хорн-Шанк) и нейросетевые подходы по идее.
11. Multiple Object Tracking (MOT): стандартная схема трекинга, типовые ошибки и смысл метрик качества. Чем отличается SORT-подобный подход от “просто детектировать на каждом кадре”?

## Модуль 4. Детектирование, сегментация, синтез и 3D-реконструкция (34–45)

1. Детектирование объектов как задача “классификация + локализация”: какие компоненты нужны и чем она отличается от простой классификации изображения.
2. **IoU**: определение, интерпретация, и как IoU используется при оценке/обучении детекторов. Почему порог 0.5 — это не “истина”, а компромисс?
3. Метрики детектора: precision/recall/F1, PR-кривая, **mAP** — что измеряет каждая и как меняется картина при изменении порога уверенности.
4. Проблема множественных откликов: почему возникает и как её решают **NMS/Soft-NMS/Cluster-NMS**. Какие побочные эффекты у “жёсткого” NMS?
5. Классический детектор: связка **HOG + SVM** (идея признаков и разделяющей поверхности). В чём сильные стороны и где он уступает современным нейросетям.
6. Двухэтапные и одноэтапные детекторы: общий принцип **R-CNN-семейства** vs **YOLO/SSD**. Компромисс точность/скорость и почему он возникает.
7. Сегментация: различие между **бинарной**, **семантической**, **интерактивной** сегментацией. Приведите пример задачи для каждого типа.
8. GraphCuts/Марковские модели: идея графовой постановки, унарные и парные потенциалы, роль регуляризации. Почему “сглаживание” границ одновременно полезно и опасно?
9. CRF в сегментации: зачем вводят CRF поверх “сырых” предсказаний (в т.ч. нейросетевых) и какие зависимости она моделирует.
10. Перенос стиля и perceptual loss: что считается “контентом”, что “стилем” (на уровне признаков), и почему style loss часто связан со статистиками распределения признаков.
11. GAN: общая схема, смысл состязания генератор-дискриминатор. В чём идея **Conditional GAN** и **CycleGAN** (какую проблему “парных данных” они обходят)?
12. 3D-реконструкция:

* различие **разреженной** и **плотной** реконструкции;
* роль **перспективной проекции** и матрицы (P = K[R|t]);
* смысл **эпиполярного ограничения** и как оно сокращает поиск соответствий;
* зачем нужен **bundle adjustment**.
