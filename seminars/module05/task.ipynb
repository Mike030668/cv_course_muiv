{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "module5-intro",
   "metadata": {},
   "source": [
    "# Семинарский ноутбук по компьютерному зрению (Module 5)\n",
    "\n",
    "В этом задании вам предстоит применить и усовершенствовать методы компьютерного зрения, рассмотренные в лекции, а также провести ряд экспериментов. Ноутбук представляет собой **шаблон**, в котором нужно дописать код и ответы в обозначенных местах.\n",
    "\n",
    "## Задачи\n",
    "\n",
    "1. **Чтение и запись видео**: Откройте видеофайл, извлеките метаданные и сохраните копию.\n",
    "2. **Оптический поток**: Вычислите поток с методом Лукаса-Канаде и визуализируйте.\n",
    "3. **Распознавание действий**: Классифицируйте действия с R3D_18 и наложите предсказания.\n",
    "4. **Трекинг объектов**: Отслеживайте объекты с YOLOv8 + ByteTrack и посчитайте метрики.\n",
    "\n",
    "> **Подсказки**: В каждой секции приведены краткие объяснения, формулы и заготовки функций. Заполняйте `TODO`-блоки и выполняйте эксперименты. Отмечайте свои наблюдения в Markdown-ячейках после выполнения кода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Установка и базовые импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown, os, sys, glob, math, time\n",
    "from pathlib import Path\n",
    "import cv2, subprocess, shlex, numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Скачивание тестового видео\n",
    "html_video = 'https://..........'\n",
    "path_video = 'data/task_video.mp4'\n",
    "video_path = Path(path_video)\n",
    "video_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "if not video_path.exists():\n",
    "    gdown.download(html_video, str(video_path), quiet=False)\n",
    "\n",
    "OUT_DIR = Path(\"out\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "def list_videos(vdir: Path):\n",
    "    vids = sorted([p for ext in (\"*.mp4\", \"*.avi\", \"*.mov\", \"*.mkv\") for p in vdir.glob(ext)])\n",
    "    if not vids:\n",
    "        raise FileNotFoundError(f\"В {vdir} не найдено видеофайлов.\")\n",
    "    return vids\n",
    "\n",
    "videos = [video_path] if video_path.exists() and video_path.is_file() else list_videos(video_path.parent)\n",
    "SRC = str(videos[0])\n",
    "\n",
    "def html_video_autosize(path: str, width: int = 512):\n",
    "    p = Path(path)\n",
    "    assert p.exists(), f\"Файл не найден: {p}\"\n",
    "    cap = cv2.VideoCapture(str(p))\n",
    "    ok, frame = cap.read()\n",
    "    cap.release()\n",
    "    assert ok, f\"Не удалось прочитать кадр из: {p}\"\n",
    "    h, w = frame.shape[:2]\n",
    "    new_h = int(h * (width / w))\n",
    "    return HTML(f'<video src=\"{p}\" width=\"{width}\" height=\"{new_h}\" controls></video>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task1",
   "metadata": {},
   "source": [
    "## 1. Чтение и запись видео\n",
    "\n",
    "Базовая операция с видео включает открытие потока, извлечение кадров и сохранение результата. Это фундамент для дальнейшей обработки.\n",
    "\n",
    "### Что нужно сделать\n",
    "- Откройте видеофайл с использованием `cv2.VideoCapture`.\n",
    "- Извлеките метаданные: FPS, разрешение, количество кадров.\n",
    "- Сохраните видео с копированием оригинальных кадров через ffmpeg.\n",
    "- Отобразите результат с помощью HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task1-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Чтение и запись видео\n",
    "def open_h264_writer(out_path, width, height, fps, crf=20, preset=\"veryfast\"):\n",
    "    cmd = [\n",
    "        'ffmpeg', '-y', '-f', 'rawvideo', '-vcodec', 'rawvideo',\n",
    "        '-s', f'{width}x{height}', '-pix_fmt', 'bgr24', '-r', str(fps),\n",
    "        '-i', '-', '-an', '-vcodec', 'libx264', '-crf', str(crf),\n",
    "        '-preset', preset, '-pix_fmt', 'yuv420p', str(out_path)\n",
    "    ]\n",
    "    return subprocess.Popen(cmd, stdin=subprocess.PIPE)\n",
    "\n",
    "# TODO: Откройте видео и извлеките метаданные\n",
    "cap = cv2.VideoCapture(SRC)\n",
    "assert cap.isOpened(), f\"Не открыть {SRC}\"\n",
    "fps = # TODO\n",
    "w = # TODO\n",
    "h = # TODO\n",
    "total_frames = # TODO\n",
    "print(f\"FPS: {fps}, Resolution: {w}x{h}, Total Frames: {total_frames}\")\n",
    "\n",
    "OUT_MP4 = OUT_DIR / \"copy_h264.mp4\"\n",
    "# TODO: Создайте writer и запишите кадры\n",
    "writer = open_h264_writer(OUT_MP4, w, h, fps)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # TODO: Запишите кадр\n",
    "\n",
    "cap.release()\n",
    "writer.stdin.close()\n",
    "writer.wait()\n",
    "\n",
    "html_video_autosize(OUT_MP4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task2",
   "metadata": {},
   "source": [
    "## 2. Оптический поток\n",
    "\n",
    "Оптический поток (Optical Flow) описывает движение объектов между кадрами. Метод Лукаса-Канаде вычисляет смещение пикселей, предполагая локальную константность движения.\n",
    "\n",
    "Формулы для градиентов:\n",
    "$$I_x = \\frac{\\partial I}{\\partial x}, \\quad I_y = \\frac{\\partial I}{\\partial y}, \\quad I_t = \\frac{\\partial I}{\\partial t}$$\n",
    "$$Au = b, \\quad u = (A^TA)^{-1} A^T b$$\n",
    "\n",
    "### Что нужно сделать\n",
    "- Вычислите оптический поток с помощью `cv2.calcOpticalFlowPyrLK`.\n",
    "- Добавьте повторное обнаружение точек, если их мало, для стабильности.\n",
    "- Визуализируйте векторы движения стрелками на кадрах.\n",
    "- Сохраните видео с оверлеем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task2-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Оптический поток\n",
    "cap = cv2.VideoCapture(SRC)\n",
    "assert cap.isOpened(), f\"Не открыть {SRC}\"\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "OUT_MP4 = OUT_DIR / \"optical_flow_lk_h264.mp4\"\n",
    "writer = open_h264_writer(OUT_MP4, w, h, fps)\n",
    "\n",
    "ret, prev_frame = cap.read()\n",
    "assert ret, \"Не удалось прочитать первый кадр\"\n",
    "prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_pts = cv2.goodFeaturesToTrack(prev_gray, maxCorners=200, qualityLevel=0.01, minDistance=30)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # TODO: Вычислите оптический поток\n",
    "    next_pts, status, err = # TODO\n",
    "    good_new = next_pts[status == 1]\n",
    "    good_old = prev_pts[status == 1]\n",
    "\n",
    "    # TODO: Визуализируйте векторы движения\n",
    "    for new, old in zip(good_new, good_old):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        cv2.arrowedLine(frame, (int(c), int(d)), (int(a), int(b)), (0, 255, 0), 2)\n",
    "    \n",
    "    writer.stdin.write(frame.tobytes())\n",
    "    prev_gray = gray.copy()\n",
    "    prev_pts = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "    # TODO: Повторное обнаружение точек, если их мало\n",
    "    if len(prev_pts) < 50:\n",
    "        new_pts = # TODO\n",
    "        if new_pts is not None:\n",
    "            prev_pts = np.vstack((prev_pts, new_pts))\n",
    "\n",
    "cap.release()\n",
    "writer.stdin.close()\n",
    "writer.wait()\n",
    "\n",
    "html_video_autosize(OUT_MP4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task3",
   "metadata": {},
   "source": [
    "## 3. Распознавание действий\n",
    "\n",
    "Распознавание действий использует 3D-свёрточные сети (например, R3D_18), обученные на датасете Kinetics-400, для классификации действий в видеоклипах.\n",
    "\n",
    "### Что нужно сделать\n",
    "- Загрузите предобученную модель R3D_18.\n",
    "- Извлеките клипы по 16 кадров, преобразуйте и классифицируйте.\n",
    "- Визуализируйте топ-1 предсказание.\n",
    "- Наложите предсказания на кадры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task3-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Распознавание действий\n",
    "cap = cv2.VideoCapture(SRC)\n",
    "assert cap.isOpened(), f\"Не открыть {SRC}\"\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "OUT_MP4 = OUT_DIR / \"action_recognition_overlay_h264.mp4\"\n",
    "writer = open_h264_writer(OUT_MP4, w, h, fps)\n",
    "\n",
    "weights = R3D_18_Weights.DEFAULT\n",
    "model = # TODO\n",
    "model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    # TODO: Преобразования (ToTensor, Resize, Normalize)\n",
    "])\n",
    "\n",
    "clip = []\n",
    "pred_label = \"\"\n",
    "NUM_FRAMES = 16\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(frame_rgb)\n",
    "    processed_frame = # TODO\n",
    "    clip.append(processed_frame)\n",
    "    if len(clip) == NUM_FRAMES:\n",
    "        clip_tensor = # TODO\n",
    "        input_tensor = # TODO\n",
    "        with torch.no_grad():\n",
    "            output = # TODO\n",
    "        top1 = torch.topk(output, 1)\n",
    "        pred_label = weights.meta[\"categories\"][top1.indices[0][0]]\n",
    "        clip = clip[1:]\n",
    "    cv2.putText(frame, pred_label if pred_label else \"Analyzing...\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    writer.stdin.write(frame.tobytes())\n",
    "\n",
    "cap.release()\n",
    "writer.stdin.close()\n",
    "writer.wait()\n",
    "\n",
    "html_video_autosize(OUT_MP4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "task4",
   "metadata": {},
   "source": [
    "## 4. Трекинг объектов\n",
    "\n",
    "Трекинг объектов использует YOLOv8 для детекции и ByteTrack для ассоциации объектов между кадрами. Добавлены метрики: скорость и время в зоне интереса.\n",
    "\n",
    "### Что нужно сделать\n",
    "- Настройте модель YOLOv8 для детекции объектов (расширьте на все классы).\n",
    "- Вычислите траектории, скорости и время в ROI.\n",
    "- Визуализируйте bbox, ID и метрики.\n",
    "- Отобразите сводку статистики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "task4-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Трекинг объектов\n",
    "def bbox_center_xyxy(box):\n",
    "    # TODO: Вычислите центр bbox\n",
    "\n",
    "def in_zone(point, box):\n",
    "    # TODO: Динамическая зона вокруг объекта\n",
    "\n",
    "def draw_metrics_label(frame, text_lines, anchor, scale=1.0):\n",
    "    # TODO: Отрисовка метрик\n",
    "\n",
    "def update_stats(obj_id, center, inroi, step_dist):\n",
    "    # TODO: Обновление статистики\n",
    "\n",
    "cap = cv2.VideoCapture(SRC)\n",
    "assert cap.isOpened(), f\"Не открыть {SRC}\"\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 25\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "OUT_MP4 = OUT_DIR / \"metrics_yolo_bytetrack_overlay_h264.mp4\"\n",
    "writer = open_h264_writer(OUT_MP4, w, h, fps)\n",
    "\n",
    "yolo = # TODO: Загрузите модель\n",
    "stats = {}\n",
    "\n",
    "for r in yolo.track(source=SRC, tracker=\"bytetrack.yaml\", conf=0.1, iou=0.5, stream=True, verbose=False):\n",
    "    frame = r.orig_img.copy()\n",
    "    H, W = frame.shape[:2]\n",
    "    SCALE = min(max(W, H) / 1920.0, 1.9)\n",
    "\n",
    "    boxes_xyxy = # TODO: Извлеките bbox\n",
    "    ids = # TODO: Извлеките ID\n",
    "    clses = # TODO: Извлеките классы\n",
    "    confs = # TODO: Извлеките уверенность\n",
    "\n",
    "    for b, oid, cls, cf in zip(boxes_xyxy, ids, clses, confs):\n",
    "        # TODO: Обработка объектов (расширьте на все классы)\n",
    "        cx, cy = bbox_center_xyxy(b)\n",
    "        # TODO: Вычислите скорость и зону\n",
    "        # TODO: Обновите статистику\n",
    "        # TODO: Отрисуйте bbox и метрики\n",
    "\n",
    "    writer.stdin.write(frame.tobytes())\n",
    "\n",
    "writer.stdin.close()\n",
    "writer.wait()\n",
    "\n",
    "# TODO: Вывод сводки\n",
    "summary = []\n",
    "for oid, st in stats.items():\n",
    "    # TODO: Рассчитайте метрики\n",
    "\n",
    "summary.sort(key=lambda x: x[0])\n",
    "print(\"\\nID | avg_speed [px/s] | time_in_zone [s] | tracked_time [s]\")\n",
    "for oid, v, tin, tt in summary:\n",
    "    print(f\"{oid:2d} | {v:14.1f} | {tin:15.2f} | {tt:14.2f}\")\n",
    "print(f\"\\nВидео с оверлеем сохранено: {OUT_MP4}\")\n",
    "\n",
    "html_video_autosize(OUT_MP4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Выводы и обсуждение\n",
    "\n",
    "После выполнения всех заданий сформулируйте краткие выводы:\n",
    "\n",
    "* Как параметры влияют на FPS и качество видео?\n",
    "* Как оптический поток справляется с быстрым движением?\n",
    "* Какие действия предсказывает модель R3D_18?\n",
    "* Как метрики трекинга помогают в анализе?\n",
    "\n",
    "Запишите свои наблюдения и выводы.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv_course)",
   "language": "python",
   "name": "cv_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
