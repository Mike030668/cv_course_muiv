{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPuLn57XEeNiOnfEC3RBzAM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Задание: 3D-реконструкция, перспектива и эпиполярная геометрия\n","\n","В этом задании вы реализуете ключевые этапы классической 3D-реконструкции:\n","\n","- Построение виртуальной сцены и проекция 3D-точек на изображение;\n","- Моделирование радиальной дисторсии;\n","- Поиск ключевых точек и построение эпиполярной геометрии;\n","- Построение карты диспаритета и получение 3D-точек.\n","\n","Заполните участки кода, помеченные как `# TODO`, и выполните соответствующие вычисления.\n"],"metadata":{"id":"gvF8FEz4Oz4s"}},{"cell_type":"markdown","source":["## Импорты и базовые функции визуализации\n","\n","Выполните следующую ячейку для подключения библиотек и определения вспомогательных функций.\n"],"metadata":{"id":"QZubsfEhO1rw"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = (6, 4)\n","plt.rcParams['figure.dpi'] = 120\n","\n","def show_img(img, title=None, cmap=None, figsize=(6,4)):\n","    plt.figure(figsize=figsize)\n","    if img.ndim == 2 or cmap is not None:\n","        plt.imshow(img, cmap=cmap)\n","    else:\n","        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","    plt.axis(\"off\")\n","    if title:\n","        plt.title(title)\n","    plt.show()\n"],"metadata":{"id":"V3cGd3R0O3KH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Построение виртуальной сцены и проекция\n","\n","Создадим виртуальную камеру и куб в 3D-пространстве. Необходимо реализовать функцию `project_points_cam`, которая проецирует 3D-точки на изображение.\n","\n","Напомним, что проекция точки \\( (X, Y, Z) \\) камеры даёт нормированные координаты \\( (x, y) = (X/Z, Y/Z) \\), а пиксельные координаты находятся по формулам:\n","\n","$$\n","u = f_x \\cdot x + c_x, \\quad v = f_y \\cdot y + c_y\n","$$\n","\n","Заполните соответствующий участок кода.\n"],"metadata":{"id":"qMKZzdCvO34g"}},{"cell_type":"code","source":["def project_points_cam(K, pts_cam):\n","    \"\"\"\n","    Перспективная проекция 3D-точек (в координатах камеры) на изображение.\n","\n","    Параметры:\n","        K: 3x3 — матрица внутренних параметров камеры\n","        pts_cam: Nx3 — массив 3D-точек в координатах камеры\n","\n","    Возвращает:\n","        Nx2 — пиксельные координаты на изображении\n","    \"\"\"\n","    pts_cam = np.asarray(pts_cam, dtype=np.float32)\n","    X = pts_cam[:, 0]\n","    Y = pts_cam[:, 1]\n","    Z = pts_cam[:, 2]\n","\n","    # TODO: избегайте деления на 0\n","    Z = np.where(Z == 0, 1e-6, Z)\n","\n","    # TODO: нормализованные координаты\n","    x = X / Z\n","    y = Y / Z\n","\n","    fx = K[0, 0]\n","    fy = K[1, 1]\n","    cx = K[0, 2]\n","    cy = K[1, 2]\n","\n","    # TODO: преобразование в пиксели\n","    u = fx * x + cx\n","    v = fy * y + cy\n","\n","    return np.stack([u, v], axis=1)\n"],"metadata":{"id":"_1XlS-C2O59Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Генерация объектов сцены: куб и пол\n","\n","Здесь мы создаём массивы 3D-точек, представляющих куб и плоскость пола.\n","Эти точки уже заданы в системе координат камеры и будут использованы\n","для перспективной проекции на изображение.\n","\n","Редактировать этот блок не требуется.\n"],"metadata":{"id":"GjYA1hdsPSb0"}},{"cell_type":"code","source":["def make_cube_cam(side=2.0, center=(0.0, 0.0, 6.0)):\n","    cx, cy, cz = center\n","    s = side / 2\n","    xs = [-s, s]\n","    ys = [-s, s]\n","    zs = [-s, s]\n","    pts = []\n","    for x in xs:\n","        for y in ys:\n","            for z in zs:\n","                pts.append([cx + x, cy + y, cz + z])\n","    return np.array(pts, dtype=np.float32)\n","\n","\n","def make_floor_cam(size=20.0, n=30, z=10.0):\n","    xs = np.linspace(-size, size, n)\n","    zs = np.linspace(0, size * 2, n)\n","    pts = []\n","    for x in xs:\n","        for zz in zs:\n","            pts.append([x, 0.0, z + zz])\n","    return np.array(pts, dtype=np.float32)\n"],"metadata":{"id":"0Rlqi1nyPW0P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Реализация поворота сцены вокруг оси Y\n","\n","Для наглядной демонстрации перспективных искажений реализуем поворот объекта\n","(например, куба) вокруг вертикальной оси Y. Это поможет понять, как меняется\n","внешний вид сцены при изменении ориентации.\n","\n","Задание: реализуйте матрицу поворота вокруг оси Y.\n"],"metadata":{"id":"XDbdEKI8Pams"}},{"cell_type":"code","source":["def rot_y(angle_deg):\n","    \"\"\"\n","    Возвращает матрицу поворота вокруг оси Y на заданный угол (в градусах).\n","    \"\"\"\n","    # TODO: переведите угол в радианы\n","    a = np.deg2rad(angle_deg)\n","    ca = np.cos(a)\n","    sa = np.sin(a)\n","\n","    # TODO: соберите и верните матрицу поворота\n","    return np.array([\n","        [ca,  0, sa],\n","        [ 0,  1,  0],\n","        [-sa, 0, ca]\n","    ], dtype=np.float32)\n"],"metadata":{"id":"dHYiTQZxPdFC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Визуализация сцены: куб в перспективе\n","\n","Скомбинируем куб, пол и виртуальную камеру в функции `render_scene`.\n","\n","Ваше задание:\n","- Проецировать 3D-точки пола и куба на изображение;\n","- Нарисовать их с помощью OpenCV-функций;\n","- Повернуть куб перед проекцией (с помощью `rot_y`).\n","\n","Ниже подготовлен шаблон функции.\n"],"metadata":{"id":"JAzBrUEAPg05"}},{"cell_type":"code","source":["W, H = 512, 384\n","background = np.full((H, W, 3), 230, dtype=np.uint8)\n","\n","CUBE_EDGES = [\n","    (0, 1), (1, 3), (3, 2), (2, 0),\n","    (4, 5), (5, 7), (7, 6), (6, 4),\n","    (0, 4), (1, 5), (2, 6), (3, 7)\n","]\n","\n","cube_cam_base = make_cube_cam(side=3.0, center=(0.0, 0.0, 8.0))\n","floor_cam     = make_floor_cam(size=25.0, n=40, z=0.0)\n","\n","def make_K(f=800.0, cx=None, cy=None):\n","    if cx is None: cx = W / 2\n","    if cy is None: cy = H / 2\n","    return np.array([[f, 0, cx],\n","                     [0, f, cy],\n","                     [0, 0, 1]], dtype=np.float32)\n","\n","def render_scene(f: float, yaw_deg: float, title: str):\n","    K = make_K(f=f, cx=W/2, cy=H/2)\n","    img = background.copy()\n","\n","    # TODO: проецируйте пол и куб\n","    floor_uv = project_points_cam(K, floor_cam)\n","\n","    center = cube_cam_base.mean(axis=0)\n","    R_yaw = rot_y(yaw_deg)\n","    cube_rel = cube_cam_base - center\n","    cube_rot = (R_yaw @ cube_rel.T).T + center\n","    cube_uv = project_points_cam(K, cube_rot)\n","\n","    # TODO: рисуем точки пола\n","    for (u, v) in floor_uv.astype(int):\n","        if 0 <= u < W and 0 <= v < H:\n","            img[v, u] = (200, 200, 200)\n","\n","    # TODO: рисуем рёбра и точки куба\n","    cube_uv_int = cube_uv.astype(int)\n","    for i, j in CUBE_EDGES:\n","        u1, v1 = cube_uv_int[i]\n","        u2, v2 = cube_uv_int[j]\n","        if (0 <= u1 < W and 0 <= v1 < H and\n","            0 <= u2 < W and 0 <= v2 < H):\n","            cv2.line(img, (u1, v1), (u2, v2), (0, 0, 255), 2)\n","\n","    for (u, v) in cube_uv_int:\n","        if 0 <= u < W and 0 <= v < H:\n","            cv2.circle(img, (u, v), 4, (0, 0, 255), -1)\n","\n","    show_img(img[..., ::-1], title=title)\n"],"metadata":{"id":"uxTSDopBPiaJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Попробуйте разные параметры визуализации\n","\n","Запустите следующий блок, чтобы увидеть, как меняется вид куба при изменении\n","фокусного расстояния и угла поворота.\n"],"metadata":{"id":"0MER-J7vPlqZ"}},{"cell_type":"code","source":["render_scene(f=800, yaw_deg=0,  title=\"f=800, yaw=0°\")\n","render_scene(f=400, yaw_deg=0,  title=\"f=400 (широкий угол), yaw=0°\")\n","render_scene(f=800, yaw_deg=30, title=\"f=800, yaw=30°\")\n"],"metadata":{"id":"Vt4H5LnDPpja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Моделирование радиальной дисторсии\n","\n","Оптические системы с линзами часто вносят искажения в изображение.\n","Наиболее распространённый тип — **радиальная дисторсия**, при которой\n","пиксели «раздуваются» или «сжимаются» по мере удаления от центра изображения.\n","\n","Здесь вы реализуете функцию, которая применяет радиальную дисторсию к координатам 2D-точек.\n","\n","Формула:\n","$$\n","x' = x(1 + k_1 r^2), \\quad y' = y(1 + k_1 r^2), \\quad r^2 = x^2 + y^2\n","$$\n","\n","Где $(x, y)$ — нормализованные координаты (до матрицы камеры),\n","а $(x', y')$ — искажённые координаты.\n"],"metadata":{"id":"gjMNdvVlP1gw"}},{"cell_type":"code","source":["def apply_radial_distortion(xy: np.ndarray, k1: float) -> np.ndarray:\n","    \"\"\"\n","    Применяет радиальную дисторсию к 2D-точкам (в нормализованных координатах).\n","\n","    Параметры:\n","        xy: Nx2 — массив [x, y] точек в нормализованных координатах (до матрицы K)\n","        k1: коэффициент радиальной дисторсии\n","\n","    Возвращает:\n","        Nx2 — искажённые координаты\n","    \"\"\"\n","    x = xy[:, 0]\n","    y = xy[:, 1]\n","    r2 = x**2 + y**2\n","\n","    # TODO: примените формулу искажений\n","    factor = 1 + k1 * r2\n","    x_dist = x * factor\n","    y_dist = y * factor\n","\n","    return np.stack([x_dist, y_dist], axis=1)\n"],"metadata":{"id":"n-BeyjhLP3pZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Применение дисторсии к изображению сцены\n","\n","Теперь вы примените радиальную дисторсию ко всем точкам пола и куба:\n","\n","1. Спроецируйте 3D-точки с помощью камеры;\n","2. Преобразуйте пиксельные координаты в нормализованные;\n","3. Примените `apply_radial_distortion`;\n","4. Пересчитайте обратно в пиксельные координаты;\n","5. Нарисуйте результат на изображении.\n","\n","Сравните сцены с и без дисторсии.\n"],"metadata":{"id":"BMfAUJKBP7az"}},{"cell_type":"code","source":["def undistort_uv_to_xy(uv: np.ndarray, K: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Переводит пиксельные координаты (u,v) в нормализованные (x,y) с использованием K.\n","\n","    Параметры:\n","        uv: Nx2 — пиксельные координаты\n","        K: 3x3 — матрица камеры\n","\n","    Возвращает:\n","        Nx2 — нормализованные координаты\n","    \"\"\"\n","    fx = K[0, 0]\n","    fy = K[1, 1]\n","    cx = K[0, 2]\n","    cy = K[1, 2]\n","\n","    # TODO: реализуйте обратное преобразование\n","    x = (uv[:, 0] - cx) / fx\n","    y = (uv[:, 1] - cy) / fy\n","\n","    return np.stack([x, y], axis=1)\n","\n","\n","def distort_scene(K, k1, yaw_deg=0.0, f=800):\n","    \"\"\"\n","    Строит изображение сцены с радиальной дисторсией.\n","\n","    - Проецирует пол и куб;\n","    - Преобразует в нормализованные координаты;\n","    - Применяет искажение;\n","    - Возвращает изображение.\n","    \"\"\"\n","    img = background.copy()\n","\n","    # Проекция\n","    floor_uv = project_points_cam(K, floor_cam)\n","\n","    center = cube_cam_base.mean(axis=0)\n","    R_yaw = rot_y(yaw_deg)\n","    cube_rel = cube_cam_base - center\n","    cube_rot = (R_yaw @ cube_rel.T).T + center\n","    cube_uv = project_points_cam(K, cube_rot)\n","\n","    # Объединяем\n","    all_uv = np.vstack([floor_uv, cube_uv])\n","    xy = undistort_uv_to_xy(all_uv, K)\n","\n","    # TODO: примените дисторсию\n","    xy_dist = apply_radial_distortion(xy, k1)\n","\n","    # Обратно в пиксели\n","    u_dist = xy_dist[:, 0] * K[0, 0] + K[0, 2]\n","    v_dist = xy_dist[:, 1] * K[1, 1] + K[1, 2]\n","    uv_dist = np.stack([u_dist, v_dist], axis=1)\n","\n","    # Визуализация\n","    for u, v in uv_dist.astype(int):\n","        if 0 <= u < W and 0 <= v < H:\n","            img[v, u] = (50, 100, 200)\n","\n","    return img\n"],"metadata":{"id":"u8lxwGhcP8qX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Визуальное сравнение сцены с и без радиальной дисторсии\n","\n","Попробуйте несколько значений коэффициента дисторсии `k1`:\n","\n","- $k_1 = 0$ — без искажений;\n","- $k_1 > 0$ — \\\"бочкообразная\\\" дисторсия;\n","- $k_1 < 0$ — \\\"подушкообразная\\\" дисторсия.\n"],"metadata":{"id":"qGoI-kmHP-fV"}},{"cell_type":"code","source":["K = make_K(f=800)\n","\n","img0 = distort_scene(K, k1=0.0)\n","img1 = distort_scene(K, k1=+0.12)\n","img2 = distort_scene(K, k1=-0.18)\n","\n","show_row([img0, img1, img2],\n","         [\"k1 = 0.0\", \"k1 = +0.12\", \"k1 = -0.18\"], figsize=(12, 4))\n"],"metadata":{"id":"nbRd2tN7P_24"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Загрузка изображений и извлечение ключевых точек\n","\n","Для эпиполярной геометрии нужны пары изображений одной сцены с небольшим параллаксом.\n","\n","В этом блоке вы:\n","1. Загрузите изображения (например, `left.jpg`, `right.jpg`);\n","2. Найдёте ключевые точки с помощью ORB;\n","3. Найдёте совпадения между ними.\n","\n","Все эти шаги можно выполнить с помощью OpenCV.\n"],"metadata":{"id":"KxFZpmRoQPfK"}},{"cell_type":"code","source":["imgL_gray = cv2.imread(\"left.jpg\", cv2.IMREAD_GRAYSCALE)\n","imgR_gray = cv2.imread(\"right.jpg\", cv2.IMREAD_GRAYSCALE)\n","\n","assert imgL_gray is not None and imgR_gray is not None, \"Изображения не загружены.\"\n","\n","# TODO: инициализируйте ORB-детектор\n","orb = cv2.ORB_create(nfeatures=5000)\n","\n","# TODO: найдите ключевые точки и дескрипторы\n","kp1, des1 = orb.detectAndCompute(imgL_gray, None)\n","kp2, des2 = orb.detectAndCompute(imgR_gray, None)\n","\n","# TODO: сопоставьте дескрипторы (matcher — Brute Force по Hamming)\n","matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n","matches = matcher.match(des1, des2)\n","\n","# Отсортируем по расстоянию\n","matches = sorted(matches, key=lambda x: x.distance)\n"],"metadata":{"id":"R2gwu1p2QQwA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Визуализация совпадений между изображениями\n","\n","Посмотрим, насколько хорошо сработало сопоставление признаков.\n"],"metadata":{"id":"04c8XA66QSUN"}},{"cell_type":"code","source":["img_matches = cv2.drawMatches(\n","    imgL_gray, kp1,\n","    imgR_gray, kp2,\n","    matches[:50], None,\n","    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",")\n","\n","show_img(img_matches, title=\"Лучшие 50 совпадений\")\n"],"metadata":{"id":"ncttNYvLQTF5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Поиск фундаментальной матрицы и фильтрация инлайеров\n","\n","Фундаментальная матрица \\( F \\) описывает эпиполярную геометрию между двумя изображениями.\n","Рассчитаем её по совпадающим точкам с помощью RANSAC.\n","\n","Вы:\n","- Извлечёте координаты точек по найденным матчам;\n","- Вычислите \\( F \\);\n","- Отфильтруете инлайеры.\n"],"metadata":{"id":"qyDrhSMMQWh-"}},{"cell_type":"code","source":["pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n","pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n","\n","# TODO: найдите фундаментальную матрицу и маску инлайеров\n","F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n","\n","print(\"F =\", F)\n"],"metadata":{"id":"c90ImVBJQZe_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Визуализация эпиполярных линий\n","\n","Построим эпиполярные линии на одном изображении, соответствующие точкам на другом.\n","\n","Для этого используем:\n","$$\n","l' = F \\cdot x, \\quad \\text{или} \\quad l = F^T \\cdot x'\n","$$\n","\n","И построим линии на изображении по уравнению \\( ax + by + c = 0 \\).\n"],"metadata":{"id":"wQB_6ivpQa5k"}},{"cell_type":"code","source":["def draw_epipolar_lines(img1, img2, pts1, pts2, F):\n","    \"\"\"\n","    Рисует эпиполярные линии на img2, соответствующие точкам на img1.\n","    \"\"\"\n","    lines = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n","    lines = lines.reshape(-1, 3)\n","\n","    img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","\n","    for (r, pt1, pt2) in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, pt2)\n","        a, b, c = r\n","        x1, y1 = 0, int(-c / b) if b != 0 else 0\n","        x2, y2 = img2.shape[1], int(-(a * x2 + c) / b) if b != 0 else 0\n","\n","        cv2.line(img2_color, (x1, y1), (x2, y2), color, 1)\n","        cv2.circle(img1_color, (x0, y0), 4, color, -1)\n","\n","    return img1_color, img2_color\n","\n","\n","# TODO: оставьте только инлайеры\n","pts1_inl = pts1[mask.ravel() == 1]\n","pts2_inl = pts2[mask.ravel() == 1]\n","\n","img1_epi, img2_epi = draw_epipolar_lines(imgL_gray, imgR_gray,\n","                                         pts1_inl, pts2_inl, F)\n","\n","show_row([img1_epi, img2_epi], [\"Точки (L)\", \"Эпиполярные линии (R)\"], figsize=(10, 5))\n"],"metadata":{"id":"W0vlzsrcQcFp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ректификация изображений (выравнивание по горизонтали)\n","\n","Ректификация преобразует изображения так, чтобы эпиполярные линии стали строго горизонтальными.\n","\n","Вы:\n","- Получите гомографии для ректификации;\n","- Преобразуете изображения;\n","- Проверите, что линии выровнены.\n"],"metadata":{"id":"kPMuVDgMQoCv"}},{"cell_type":"code","source":["def rectify_uncalibrated(img1, img2, pts1, pts2, F):\n","    \"\"\"\n","    Ректифицирует изображения с использованием фундаментальной матрицы.\n","    \"\"\"\n","    h, w = img1.shape[:2]\n","\n","    # TODO: найдите гомографии H1 и H2\n","    retval, H1, H2 = cv2.stereoRectifyUncalibrated(\n","        pts1, pts2, F, imgSize=(w, h)\n","    )\n","\n","    assert retval, \"Ректификация не удалась\"\n","\n","    # TODO: преобразуйте изображения\n","    img1_rect = cv2.warpPerspective(img1, H1, (w, h))\n","    img2_rect = cv2.warpPerspective(img2, H2, (w, h))\n","\n","    return img1_rect, img2_rect, H1, H2\n","\n","\n","imgL_rect, imgR_rect, H1, H2 = rectify_uncalibrated(\n","    imgL_gray, imgR_gray, pts1_inl, pts2_inl, F\n",")\n","\n","show_row([imgL_rect, imgR_rect], [\"Левое (ректифицировано)\", \"Правое (ректифицировано)\"], figsize=(10, 4))\n"],"metadata":{"id":"ai9miJZIQpqc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Проверка: эпиполярные линии после ректификации\n","\n","Проверьте, что после ректификации соответствующие точки лежат на одной горизонтали.\n","Для этого нарисуем горизонтальные сетки поверх изображений.\n"],"metadata":{"id":"eTsb9sfMQrCc"}},{"cell_type":"code","source":["def show_with_grid(img, n_lines=15, color=(0, 255, 0)):\n","    img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n","    h, w = img.shape\n","    for y in np.linspace(0, h, n_lines, dtype=int):\n","        cv2.line(img_color, (0, y), (w, y), color, 1)\n","    return img_color\n","\n","show_row(\n","    [show_with_grid(imgL_rect), show_with_grid(imgR_rect)],\n","    [\"Сетка на левом\", \"Сетка на правом\"], figsize=(10, 4)\n",")\n"],"metadata":{"id":"8lrk1N-hQskx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Получение карты диспаритета\n","\n","Используем OpenCV `StereoSGBM` для расчёта карты смещений (disparity) между парой изображений.\n","\n","Чем ближе объект — тем больше disparity.\n"],"metadata":{"id":"4o6idz1HQt6G"}},{"cell_type":"code","source":["# TODO: настройте параметры стерео-алгоритма\n","stereo = cv2.StereoSGBM_create(\n","    minDisparity=0,\n","    numDisparities=64,  # должно делиться на 16\n","    blockSize=7,\n","    P1=8*3*7**2,\n","    P2=32*3*7**2,\n","    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",")\n","\n","disp_raw = stereo.compute(imgL_rect, imgR_rect).astype(np.float32) / 16.0\n","\n","# Преобразуем недопустимые значения в NaN\n","disp = np.where(disp_raw <= 0, np.nan, disp_raw)\n","\n","plt.figure(figsize=(8, 4))\n","plt.imshow(disp, cmap=\"plasma\")\n","plt.colorbar(label=\"disparity\")\n","plt.title(\"Карта диспаритета\")\n","plt.axis(\"off\")\n","plt.show()\n"],"metadata":{"id":"ZrzfrDVqQvmf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Увеличенный фрагмент карты диспаритета\n","\n","Рассмотрим фрагмент изображения, чтобы лучше увидеть разницу в глубине между объектами.\n"],"metadata":{"id":"ietn7pAWQxNB"}},{"cell_type":"code","source":["def show_crop_with_disp(img, disp, x0, y0, dx, dy):\n","    img_crop = img[y0:y0+dy, x0:x0+dx]\n","    disp_crop = disp[y0:y0+dy, x0:x0+dx]\n","\n","    show_row([img_crop, disp_crop],\n","             [\"Фрагмент изображения\", \"disparity-фрагмент\"],\n","             figsize=(10, 4), cmap2=\"plasma\")\n","\n","\n","show_crop_with_disp(imgL_rect, disp, x0=150, y0=80, dx=150, dy=100)\n"],"metadata":{"id":"RehnjDjnQzXq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Визуализация облака точек из disparity\n","\n","На основе значений disparity можно восстановить относительную глубину сцены.\n","\n","В этом задании вы:\n","- Преобразуете disparity в координаты \\( X, Y, Z \\);\n","- Отобразите результат в 3D.\n"],"metadata":{"id":"bDpC_TIWQ8hf"}},{"cell_type":"code","source":["from mpl_toolkits.mplot3d import Axes3D  # noqa\n","from matplotlib import cm\n","\n","def disparity_to_point_cloud(disp, step=2, max_points=8000):\n","    \"\"\"\n","    Преобразует карту disparity в облако точек (X, Y, Z), где\n","    Z ~ 1 / disparity (относительная глубина).\n","\n","    step — прореживание (чем больше, тем реже точки);\n","    max_points — максимальное число отображаемых точек.\n","    \"\"\"\n","    h, w = disp.shape\n","\n","    # Сетка координат\n","    ys, xs = np.mgrid[0:h:step, 0:w:step]\n","    ds = disp[0:h:step, 0:w:step]\n","\n","    mask = ~np.isnan(ds)\n","    xs = xs[mask].astype(np.float32)\n","    ys = ys[mask].astype(np.float32)\n","    ds = ds[mask].astype(np.float32)\n","\n","    if len(xs) == 0:\n","        raise RuntimeError(\"Нет валидных значений disparity.\")\n","\n","    # TODO: глубина обратно пропорциональна disparity\n","    Z = 1.0 / (ds + 1e-6)\n","    Z = (Z - Z.min()) / (Z.max() - Z.min() + 1e-6)\n","\n","    if len(xs) > max_points:\n","        idx = np.random.choice(len(xs), size=max_points, replace=False)\n","        xs, ys, Z = xs[idx], ys[idx], Z[idx]\n","\n","    return xs, ys, Z\n","\n","\n","# Построение облака точек\n","X, Y, Z = disparity_to_point_cloud(disp)\n","\n","fig = plt.figure(figsize=(8, 6))\n","ax = fig.add_subplot(111, projection='3d')\n","p = ax.scatter(X, Y, Z, c=Z, cmap=\"plasma\", s=1)\n","\n","ax.set_xlabel(\"X (pixels)\")\n","ax.set_ylabel(\"Y (pixels)\")\n","ax.set_zlabel(\"Relative depth\")\n","ax.set_title(\"3D-точки из disparity\")\n","\n","fig.colorbar(p, label=\"Relative depth\")\n","plt.show()\n"],"metadata":{"id":"jTNiAA-TQ9_6"},"execution_count":null,"outputs":[]}]}